{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech-to-Text.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSKH8uiP8E2xcMhp+ySE7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheikmohdimran/Experiments_2021/blob/main/Hackathon_Final_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "Pwag2Oy5OyMV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PDjmCKOQOw9k",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install and Import Dependencies\n",
        "\n",
        "# this assumes that you have a relevant version of PyTorch installed\n",
        "!pip install -qqq omegaconf ipymarkup pydub torchaudio fastcore gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "SAMPLING_RATE = 16000\n",
        "\n",
        "import torch\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "from IPython.display import Audio\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import zipfile\n",
        "import torchaudio\n",
        "from glob import glob\n",
        "import difflib\n",
        "import re\n",
        "from ipymarkup import show_span_box_markup\n",
        "import torch\n",
        "from fastcore.basics import patch_to\n",
        "import soundfile as sf\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fADPslVz4JeZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model & helper functions - Speech to Text\n",
        "\n",
        "# Voice Activity Detector\n",
        "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
        "                              model='silero_vad',\n",
        "                              force_reload=True,\n",
        "                              onnx=False)\n",
        "\n",
        "(get_speech_timestamps,\n",
        " save_audio,\n",
        " read_audio,\n",
        " VADIterator,\n",
        " collect_chunks) = utils\n",
        "\n",
        " \n",
        "# Speech to Text\n",
        "device = torch.device('cpu')  # gpu also works, but our models are fast enough for CPU\n",
        "model_stt, decoder, utils_stt = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                       model='silero_stt',\n",
        "                                       language='en', # also available 'de', 'es'\n",
        "                                       device=device)\n",
        "(_, _, _, prepare_model_input) = utils_stt  # see function signature for details"
      ],
      "metadata": {
        "id": "T53h6dJaO3Sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6a0a6d-2bec-47f0-be39-737210480967",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/snakers4/silero-vad/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Using cache found in /root/.cache/torch/hub/snakers4_silero-models_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pronunciation checker"
      ],
      "metadata": {
        "id": "ar3S1feYSFsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper functions\n",
        "def tokenize(s):\n",
        "    return re.split('\\s+', s)\n",
        "def untokenize(ts):\n",
        "    return ' '.join(ts)\n",
        "\n",
        "# Compare ground truth to transcribed text        \n",
        "def equalize(s1, s2):\n",
        "    l1 = tokenize(s1)\n",
        "    l2 = tokenize(s2)\n",
        "    res1 = []\n",
        "    res2 = []\n",
        "    prev = difflib.Match(0,0,0)\n",
        "    for match in difflib.SequenceMatcher(a=l1, b=l2).get_matching_blocks():\n",
        "        if (prev.a + prev.size != match.a):\n",
        "            for i in range(prev.a + prev.size, match.a):\n",
        "                res2 += ['_' * len(l1[i])]\n",
        "            res1 += l1[prev.a + prev.size:match.a]\n",
        "        if (prev.b + prev.size != match.b):\n",
        "            for i in range(prev.b + prev.size, match.b):\n",
        "                res1 += ['_' * len(l2[i])]\n",
        "            res2 += l2[prev.b + prev.size:match.b]\n",
        "        res1 += l1[match.a:match.a+match.size]\n",
        "        res2 += l2[match.b:match.b+match.size]\n",
        "        prev = match\n",
        "    return untokenize(res1), untokenize(res2)\n",
        "\n",
        "# Identify misspoken words\n",
        "def find_spans(prediction, ground_truth):\n",
        "  new1, new2 = equalize(prediction, ground_truth)\n",
        "  wrong_list=[]\n",
        "  for i in range(len(new1.split())):\n",
        "    if new1.split()[i] != new2.split()[i]:\n",
        "      a = new2.split()[i].replace(\"_\", \"\")\n",
        "      if a: wrong_list.append(a)\n",
        "\n",
        "  spans=[]\n",
        "  for i in range(len(wrong_list)):\n",
        "    m = re.search(wrong_list[i],ground_truth)\n",
        "    spans.append(([m.start(),m.end(),'‚ùå']))\n",
        "\n",
        "  return wrong_list,spans\n",
        "\n",
        "# Create list of tuples for gradio display\n",
        "def create_highlights(ground_truth,wrong_list):\n",
        "  a = ground_truth.split(\" \")\n",
        "  b=[]\n",
        "  c=[]\n",
        "  for i in a:\n",
        "    c.append('DET' if i in wrong_list else None)\n",
        "    c.append(\"\")\n",
        "    b.append(i)\n",
        "    b.append(\" \")\n",
        "\n",
        "  return list(zip(b,c))\n",
        "\n",
        "# Patch function from library to save file\n",
        "@patch_to(gr.processing_utils)\n",
        "def audio_to_file(sample_rate, data, filename):\n",
        "  sf.write(filename, data, sample_rate)\n"
      ],
      "metadata": {
        "id": "st5egO7PPFqt",
        "cellView": "form"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pronunciation helper"
      ],
      "metadata": {
        "id": "QFWkNkhTR3ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model - Text to Speech\n",
        "language = 'en'\n",
        "speaker = 'lj_v2'\n",
        "sample_rate = 16000\n",
        "device = torch.device('cpu')\n",
        "\n",
        "model_tts, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                     model='silero_tts',\n",
        "                                     language=language,\n",
        "                                     speaker=speaker)\n",
        "model_tts.to(device)  # gpu or cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTbpjZICRHq_",
        "outputId": "08c3d1e8-4e90-4c5e-bde5-1dfb66a6c92c",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/snakers4_silero-models_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth ='this is a sample test for speech to text models'\n",
        "\n",
        "def transcribe(file):\n",
        "    prediction=[]\n",
        "    waveform = read_audio(file)\n",
        "    speech_timestamps = get_speech_timestamps(waveform, model, sampling_rate=SAMPLING_RATE)\n",
        "    for i in speech_timestamps:\n",
        "      input = prepare_model_input(waveform[i['start']: i['end']].unsqueeze(0),device=device)\n",
        "      output = model_stt(input).squeeze()\n",
        "      prediction.append(decoder(output.cpu()))\n",
        "    print(prediction[0])\n",
        "    wrongs,_=find_spans(prediction[0], ground_truth)\n",
        "    output = create_highlights(ground_truth,wrongs)\n",
        "    print(wrongs)\n",
        "    audio = model_tts.apply_tts(texts=wrongs,sample_rate=SAMPLING_RATE)\n",
        "    audio_np=[i.numpy() for i in audio]\n",
        "    return output,(SAMPLING_RATE,np.hstack(audio_np))"
      ],
      "metadata": {
        "id": "muUkQxmW08Ba"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=transcribe, \n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type='filepath')\n",
        "    ],\n",
        "    outputs=[\n",
        "             gr.outputs.HighlightedText(color_map={ \"\": \"\", }), #\"text\",\n",
        "             \"audio\"\n",
        "\n",
        "    ],\n",
        "    layout=\"horizontal\",\n",
        "    theme=\"huggingface\",\n",
        "    title=\"NUHA - Your personal reading assistant\",\n",
        "    description=\"Please read this: \"+ground_truth\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "mGXm9imuV7_4",
        "outputId": "42154b95-942f-4eca-8f2a-1dcf092bf943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Your interface requires microphone or webcam permissions - this may cause issues in Colab. Use the External URL in case of issues.\n",
            "Running on public URL: https://30628.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://30628.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ff789e91d90>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a sample test force speech to text models\n",
            "['for']\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7ff78b74c410>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://30628.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c85M_c-ZiEHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}